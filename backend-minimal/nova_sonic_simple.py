import os
import asyncio
import base64
import json
import uuid
import pyaudio
import boto3
from aws_sdk_bedrock_runtime.client import BedrockRuntimeClient, InvokeModelWithBidirectionalStreamOperationInput
from aws_sdk_bedrock_runtime.models import InvokeModelWithBidirectionalStreamInputChunk, BidirectionalInputPayloadPart
from aws_sdk_bedrock_runtime.config import Config, HTTPAuthSchemeResolver, SigV4AuthScheme
from smithy_aws_core.credentials_resolvers.environment import EnvironmentCredentialsResolver
from smithy_aws_core.credentials_resolvers.static import StaticCredentialsResolver
from smithy_aws_core.identity import AWSCredentialsIdentity
from smithy_core.interfaces.identity import IdentityProperties
from tools import ToolManager

# Audio configuration
INPUT_SAMPLE_RATE = 16000
OUTPUT_SAMPLE_RATE = 24000
CHANNELS = 1
FORMAT = pyaudio.paInt16
CHUNK_SIZE = 512  # Reduced for better responsiveness

def get_aws_credentials_resolver():
    """Get AWS credentials using boto3 (supports environment variables, profiles, etc.)"""
    try:
        # Use boto3 to resolve credentials (supports full credential chain)
        session = boto3.Session()
        credentials = session.get_credentials()
        
        if credentials:
            # Create AWSCredentialsIdentity for smithy
            aws_credentials = AWSCredentialsIdentity(
                access_key_id=credentials.access_key,
                secret_access_key=credentials.secret_key,
                session_token=credentials.token
            )
            # Return static resolver with the credentials (using keyword argument)
            return StaticCredentialsResolver(credentials=aws_credentials)
        else:
            # Fall back to environment resolver
            return EnvironmentCredentialsResolver()
    except Exception as e:
        print(f"Warning: Could not resolve AWS credentials via boto3: {e}")
        # Fall back to environment resolver
        return EnvironmentCredentialsResolver()

class SimpleNovaSonic:
    def __init__(self, model_id='amazon.nova-sonic-v1:0', region='us-east-1'):
        self.model_id = model_id
        self.region = region
        self.client = None
        self.stream = None
        self.response = None
        self.is_active = False
        self.prompt_name = str(uuid.uuid4())
        self.content_name = str(uuid.uuid4())
        self.audio_content_name = str(uuid.uuid4())
        self.audio_queue = asyncio.Queue()
        self.event_queue = asyncio.Queue()
        self.role = None
        self.display_assistant_text = False
        self.tool_manager = ToolManager()
        self.barge_in = False  # Added barge-in flag
        
    def _initialize_client(self):
        """Initialize the Bedrock client."""
        config = Config(
            endpoint_uri=f"https://bedrock-runtime.{self.region}.amazonaws.com",
            region=self.region,
            aws_credentials_identity_resolver=get_aws_credentials_resolver(),
            http_auth_scheme_resolver=HTTPAuthSchemeResolver(),
            http_auth_schemes={"aws.auth#sigv4": SigV4AuthScheme()}
        )
        self.client = BedrockRuntimeClient(config=config)
    
    async def send_event(self, event_json):
        """Send an event to the stream."""
        event = InvokeModelWithBidirectionalStreamInputChunk(
            value=BidirectionalInputPayloadPart(bytes_=event_json.encode('utf-8'))
        )
        await self.stream.input_stream.send(event)
    
    async def start_session(self):
        """Start a new session with Nova Sonic."""
        if not self.client:
            self._initialize_client()
            
        # Initialize the stream
        self.stream = await self.client.invoke_model_with_bidirectional_stream(
            InvokeModelWithBidirectionalStreamOperationInput(model_id=self.model_id)
        )
        self.is_active = True
        
        # Send session start event
        session_start = '''
        {
          "event": {
            "sessionStart": {
              "inferenceConfiguration": {
                "maxTokens": 1024,
                "topP": 0.9,
                "temperature": 0.7
              }
            }
          }
        }
        '''
        await self.send_event(session_start)
        
        # Create prompt start event with tool configuration
        prompt_start_data = {
            "event": {
                "promptStart": {
                    "promptName": self.prompt_name,
                    "textOutputConfiguration": {
                "mediaType": "text/plain"
                    },
                    "audioOutputConfiguration": {
                "mediaType": "audio/lpcm",
                "sampleRateHertz": 24000,
                "sampleSizeBits": 16,
                "channelCount": 1,
                "voiceId": "matthew",
                "encoding": "base64",
                "audioType": "SPEECH"
                    },
                    "toolUseOutputConfiguration": {
                        "mediaType": "application/json"
                    },
                    "toolConfiguration": {
                        "tools": self.tool_manager.get_tool_configs()
                    }
                }
            }
        }
        
        await self.send_event(json.dumps(prompt_start_data))
        
        # Send system prompt
        text_content_start = f'''
        {{
            "event": {{
                "contentStart": {{
                    "promptName": "{self.prompt_name}",
                    "contentName": "{self.content_name}",
                    "type": "TEXT",
                    "interactive": true,
                    "role": "SYSTEM",
                    "textInputConfiguration": {{
                        "mediaType": "text/plain"
                    }}
                }}
            }}
        }}
        '''
        await self.send_event(text_content_start)
        
        system_prompt = "You are a professional hotel receptionist AI. Your role: You assist guests ONLY with hotel-related information and services. You do NOT answer questions unrelated to the hotel. Your personality: Warm, polite, calm, and welcoming. Friendly and respectful at all times. Never arrogant, never commanding, never robotic. Speak like trained front-desk hotel staff. Conversation rules: 1. Always greet the guest politely before asking any question. 2. Use soft and respectful language like 'May I please...', 'Could you please...', 'I'd be happy to help'. 3. Never use commanding language such as 'Tell me', 'Provide', 'Enter'. 4. Always explain WHY you are asking for information. 5. Always thank the guest after receiving details. 6. Keep sentences short and natural for voice responses. Hotel-related topics you ARE allowed to answer: Room services (housekeeping, towels, cleaning), Food and beverage orders, Maintenance or engineering issues, Reception and front-desk queries, Hotel facilities (restaurant, timings, Wi-Fi, check-in/check-out), Billing or payment assistance, Guest complaints related to hotel stay. If the guest asks a NON-hotel-related question: Do NOT answer it. Respond politely with: 'I'm sorry, I'm only able to assist with hotel-related requests and information.' Primary flow: 1. Greet the guest 2. Understand the request 3. Ask for room number politely if required 4. Acknowledge the request 5. Confirm action taken 6. Offer further help. Default greeting: 'Hello! Welcome to our hotel! How may I assist you today?' Asking room number: 'May I please know your room number so I can assist you better?' After receiving room number: 'Thank you! I'll take care of that for you right away.' Polite refusal for non-hotel queries: 'I'm sorry, I'm only able to assist with hotel-related questions and services.' Closing line: 'Is there anything else I can help you with?' Important: If you are using a tool, mention that you are gathering information."

        text_input = f'''
        {{
            "event": {{
                "textInput": {{
                    "promptName": "{self.prompt_name}",
                    "contentName": "{self.content_name}",
                    "content": "{system_prompt}"
                }}
            }}
        }}
        '''
        await self.send_event(text_input)
        
        text_content_end = f'''
        {{
            "event": {{
                "contentEnd": {{
                    "promptName": "{self.prompt_name}",
                    "contentName": "{self.content_name}"
                }}
            }}
        }}
        '''
        await self.send_event(text_content_end)
        
        # Start processing responses
        self.response = asyncio.create_task(self._process_responses())
    
    async def start_audio_input(self):
        """Start audio input stream."""
        audio_content_start = f'''
        {{
            "event": {{
                "contentStart": {{
                    "promptName": "{self.prompt_name}",
                    "contentName": "{self.audio_content_name}",
                    "type": "AUDIO",
                    "interactive": true,
                    "role": "USER",
                    "audioInputConfiguration": {{
                        "mediaType": "audio/lpcm",
                        "sampleRateHertz": 16000,
                        "sampleSizeBits": 16,
                        "channelCount": 1,
                        "audioType": "SPEECH",
                        "encoding": "base64"
                    }}
                }}
            }}
        }}
        '''
        await self.send_event(audio_content_start)
    
    async def send_audio_chunk(self, audio_bytes):
        """Send an audio chunk to the stream."""
        if not self.is_active:
            return
            
        blob = base64.b64encode(audio_bytes)
        audio_event = f'''
        {{
            "event": {{
                "audioInput": {{
                    "promptName": "{self.prompt_name}",
                    "contentName": "{self.audio_content_name}",
                    "content": "{blob.decode('utf-8')}"
                }}
            }}
        }}
        '''
        await self.send_event(audio_event)
    
    async def end_audio_input(self):
        """End audio input stream."""
        audio_content_end = f'''
        {{
            "event": {{
                "contentEnd": {{
                    "promptName": "{self.prompt_name}",
                    "contentName": "{self.audio_content_name}"
                }}
            }}
        }}
        '''
        await self.send_event(audio_content_end)
    
    async def end_session(self):
        """End the session."""
        if not self.is_active:
            return
            
        prompt_end = f'''
        {{
            "event": {{
                "promptEnd": {{
                    "promptName": "{self.prompt_name}"
                }}
            }}
        }}
        '''
        await self.send_event(prompt_end)
        
        session_end = '''
        {
            "event": {
                "sessionEnd": {}
            }
        }
        '''
        await self.send_event(session_end)
        # close the stream
        await self.stream.input_stream.close()
    
    async def _process_responses(self):
        """Process responses from Nova Sonic."""
        try:
            while self.is_active:
                output = await self.stream.await_output()
                result = await output[1].receive()
                
                if result.value and result.value.bytes_:
                    response_data = result.value.bytes_.decode('utf-8')
                    json_data = json.loads(response_data)
                    
                    if 'event' in json_data:
                        await self.event_queue.put(json.dumps(json_data))
                        
                        # Handle tool use events
                        if 'toolUse' in json_data['event']:
                            tool_use = json_data['event']['toolUse']
                            tool_name = tool_use['toolName']
                            tool_use_id = tool_use['toolUseId']
                            prompt_name = tool_use['promptName']
                            content = json.loads(tool_use['content'])
                            tool_content_name = str(uuid.uuid4())
                            
                            print(f"Processing tool use: {tool_name}")
                            
                            # Send tool execution progress event
                            tool_progress_event = {
                                "event": {
                                    "toolUiOutput": {
                                        "type": "tool_exec_progress",
                                        "content": {
                                            "status": "started",
                                            "toolName": tool_name
                                        }
                                    }
                                }
                            }
                            # Send directly to websocket instead of queuing
                            await self.event_queue.put(json.dumps(tool_progress_event))
                            # Add a small delay to ensure the event is processed
                            await asyncio.sleep(0.1)
                            
                            # Get tool configuration from registry
                            tool_configs = self.tool_manager.get_tool_configs()
                            tool_config = next((
                                tool["toolSpec"] 
                                for tool in tool_configs 
                                if tool["toolSpec"]["name"] == tool_name
                            ), None)
                            short_description = tool_config.get("description", "") if tool_config else ""
                            
                            # Send tool content start event
                            tool_start_event = {
                                "event": {
                                    "contentStart": {
                                        "promptName": prompt_name,
                                        "contentName": tool_content_name,
                                        "type": "TOOL",
                                        "role": "TOOL",
                                        "interactive": False,
                                        "shortDescription": short_description,
                                        "toolResultInputConfiguration": {
                                            "toolUseId": tool_use_id,
                                            "type": "TEXT",
                                            "textInputConfiguration": {
                                                "mediaType": "text/plain"
                                            }
                                        }
                                    }
                                }
                            }
                            await self.send_event(json.dumps(tool_start_event))
                            
                            # Execute the tool
                            try:
                                result = await self.tool_manager.execute_tool(tool_name, content)
                                
                                # Send tool execution complete event before the result
                                tool_complete_event = {
                                    "event": {
                                        "toolUiOutput": {
                                            "type": "tool_exec_progress",
                                            "content": {
                                                "status": "completed",
                                                "toolName": tool_name
                                            }
                                        }
                                    }
                                }
                                await self.event_queue.put(json.dumps(tool_complete_event))
                                # Add a small delay to ensure the event is processed
                                await asyncio.sleep(0.1)

                                # Send tool result to model
                                tool_result = {
                                    "event": {
                                        "toolResult": {
                                            "promptName": prompt_name,
                                            "contentName": tool_content_name,
                                            "content": json.dumps(result["model_result"])
                                        }
                                    }
                                }
                                await self.send_event(json.dumps(tool_result))
                                print(f"Tool model result sent: {result['model_result']}")

                                # Send UI result if available
                                if "ui_result" in result:
                                    ui_result = {
                                        "event": {
                                            "toolUiOutput": result["ui_result"]
                                        }
                                    }
                                    await self.event_queue.put(json.dumps(ui_result))
                                    print(f"Tool UI result queued: {result['ui_result']}")

                                # Send tool content end event only after successful result
                                tool_end_event = {
                                    "event": {
                                        "contentEnd": {
                                            "promptName": prompt_name,
                                            "contentName": tool_content_name,
                                            "type": "TOOL",
                                            "stopReason": "TOOL_USE"
                                        }
                                    }
                                }
                                await self.send_event(json.dumps(tool_end_event))
                                
                            except Exception as e:
                                print(f"Error executing tool {tool_name}: {e}")
                                # Send error result before ending content
                                error_result = {
                                    "event": {
                                        "toolResult": {
                                            "promptName": prompt_name,
                                            "contentName": tool_content_name,
                                            "content": json.dumps({"error": str(e)})
                                        }
                                    }
                                }
                                await self.send_event(json.dumps(error_result))
                                
                                # Send tool execution complete event even on error
                                tool_complete_event = {
                                    "event": {
                                        "toolUiOutput": {
                                            "type": "tool_exec_progress",
                                            "content": {
                                                "status": "completed",
                                                "toolName": tool_name
                                            }
                                        }
                                    }
                                }
                                await self.event_queue.put(json.dumps(tool_complete_event))
                                await asyncio.sleep(0.1)
                                
                                # Send content end event even in case of error
                                tool_end_event = {
                                    "event": {
                                        "contentEnd": {
                                            "promptName": prompt_name,
                                            "contentName": tool_content_name,
                                            "type": "TOOL",
                                            "stopReason": "ERROR"
                                        }
                                    }
                                }
                                await self.send_event(json.dumps(tool_end_event))
                            
                        # Handle other events (contentStart, textOutput, audioOutput)
                        elif 'contentStart' in json_data['event']:
                            content_start = json_data['event']['contentStart'] 
                            # set role
                            self.role = content_start['role']
                            # Check for speculative content
                            if 'additionalModelFields' in content_start:
                                additional_fields = json.loads(content_start['additionalModelFields'])
                                if additional_fields.get('generationStage') == 'SPECULATIVE':
                                    self.display_assistant_text = True
                                else:
                                    self.display_assistant_text = False
                                
                        # Handle text output event
                        elif 'textOutput' in json_data['event']:
                            text = json_data['event']['textOutput']['content']
                            
                            # Check for barge-in signal
                            if '{ "interrupted" : true }' in text:
                                print("Barge-in detected, stopping audio output")
                                self.barge_in = True
                                # Send barge-in event to frontend
                                barge_in_event = {
                                    "event": {
                                        "toolUiOutput": {
                                            "type": "barge_in",
                                            "content": {
                                                "status": "interrupted"
                                            }
                                        }
                                    }
                                }
                                await self.event_queue.put(json.dumps(barge_in_event))
                                continue
                           
                            if (self.role == "ASSISTANT" and self.display_assistant_text):
                                print(f"Assistant: {text}")
                            elif self.role == "USER":
                                print(f"User: {text}")
                        
                        # Handle audio output
                        elif 'audioOutput' in json_data['event']:
                            if not self.barge_in:  # Only process audio if no barge-in
                                audio_content = json_data['event']['audioOutput']['content']
                                audio_bytes = base64.b64decode(audio_content)
                                await self.audio_queue.put(audio_bytes)

        except Exception as e:
            print(f"Error processing responses: {e}")
            if hasattr(e, '__traceback__'):
                import traceback
                traceback.print_exc()
    
    async def play_audio(self):
        """Play audio responses."""
        p = pyaudio.PyAudio()
        stream = p.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=OUTPUT_SAMPLE_RATE,
            output=True,
            frames_per_buffer=CHUNK_SIZE
        )
        
        try:
            while self.is_active:
                try:
                    # Check for barge-in flag
                    if self.barge_in:
                        # Clear the audio queue
                        while not self.audio_queue.empty():
                            try:
                                self.audio_queue.get_nowait()
                            except asyncio.QueueEmpty:
                                break
                        self.barge_in = False
                        await asyncio.sleep(0.05)
                        continue

                    # Get audio data with timeout
                    audio_data = await asyncio.wait_for(
                        self.audio_queue.get(),
                        timeout=0.1
                    )

                    if audio_data and self.is_active:
                        # Write audio in smaller chunks to allow for quicker barge-in response
                        for i in range(0, len(audio_data), CHUNK_SIZE):
                            if self.barge_in:
                                break
                            chunk = audio_data[i:min(i + CHUNK_SIZE, len(audio_data))]
                            stream.write(chunk)
                            await asyncio.sleep(0.001)  # Small yield to allow other tasks to run

                except asyncio.TimeoutError:
                    continue
                except Exception as e:
                    print(f"Error playing audio: {e}")
                    await asyncio.sleep(0.05)

        except Exception as e:
            print(f"Error in audio playback loop: {e}")
        finally:
            stream.stop_stream()
            stream.close()
            p.terminate()
            print("Audio playing stopped.")

    async def capture_audio(self):
        """Capture audio from microphone and send to Nova Sonic."""
        p = pyaudio.PyAudio()
        stream = p.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=INPUT_SAMPLE_RATE,
            input=True,
            frames_per_buffer=CHUNK_SIZE
        )
        
        print("Starting audio capture. Speak into your microphone...")
        print("Press Enter to stop...")
        
        await self.start_audio_input()
        
        try:
            while self.is_active:
                audio_data = stream.read(CHUNK_SIZE, exception_on_overflow=False)
                await self.send_audio_chunk(audio_data)
                await asyncio.sleep(0.01)
        except Exception as e:
            print(f"Error capturing audio: {e}")
        finally:
            stream.stop_stream()
            stream.close()
            p.terminate()
            print("Audio capture stopped.")
            await self.end_audio_input()

async def main():
    # Create Nova Sonic client
    nova_client = SimpleNovaSonic()
    
    # Start session
    await nova_client.start_session()
    
    # Start audio playback task
    playback_task = asyncio.create_task(nova_client.play_audio())
    
    # Start audio capture task
    capture_task = asyncio.create_task(nova_client.capture_audio())
    
    # Wait for user to press Enter to stop
    await asyncio.get_event_loop().run_in_executor(None, input)
    
    # End session
    nova_client.is_active = False
    
    # First cancel the tasks
    tasks = []
    if not playback_task.done():
        tasks.append(playback_task)
    if not capture_task.done():
        tasks.append(capture_task)
    for task in tasks:
        task.cancel()
    if tasks:
        await asyncio.gather(*tasks, return_exceptions=True)
    
    # cancel the response task
    if nova_client.response and not nova_client.response.done():
        nova_client.response.cancel()
    
    await nova_client.end_session()
    print("Session ended")

# AWS credentials are automatically loaded from:
# 1. Environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION)
# 2. AWS profiles (~/.aws/credentials and ~/.aws/config)
# 3. EC2 instance metadata
# 4. ECS container credentials
# 5. IAM roles for service accounts (when running in EKS)
#
# If you don't have credentials set up, run: aws configure
# Or set environment variables manually if needed

if __name__ == "__main__":
    asyncio.run(main())

